{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load checkpoint and imports"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T09:37:47.495677Z",
     "start_time": "2024-06-30T09:37:47.492184Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import sys\n",
    "parent_dir = \"/Midgard/home/farzantn/phd/Olfaction/MoLFormer_N2024\"\n",
    "sys.path.append(parent_dir)\n",
    "parent_dir=\"/Midgard/home/farzantn/mambaforge/envs/MolTran_CUDA11_cuda/lib/python3.8\"\n",
    "sys.path.append(parent_dir)"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T09:37:51.083141Z",
     "start_time": "2024-06-30T09:37:48.267015Z"
    }
   },
   "source": [
    "device_name='cuda'\n",
    "# \n",
    "# from datetime import datetime\n",
    "# from argparse import Namespace\n",
    "# import yaml\n",
    "import os\n",
    "# import pandas as pd\n",
    "# from rdkit import Chem\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "print(os.getcwd())\n",
    "# import torch\n",
    "# from sklearn.decomposition import PCA\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "from custom_utils.tokenizer.tokenizer import MolTranBertTokenizer\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# import rdkit\n",
    "# \n",
    "# from openpom.utils.data_utils import get_class_imbalance_ratio\n",
    "# from openpom.feat.graph_featurizer import GraphFeaturizer, GraphConvConstants\n",
    "# from openpom.utils.loss import CustomMultiLabelLoss\n",
    "print(os.getcwd())\n",
    "# from utils.mol_loss import MolCustomMultiLabelLoss\n",
    "# from openpom.utils.loss import CustomMultiLabelLoss\n",
    "\n",
    "# from openpom.feat.graph_featurizer import GraphFeaturizer, GraphConvConstants\n",
    "\n",
    "# import deepchem as dc\n",
    "# import rdkit\n",
    "from utils.gs_lf import *\n",
    "with open('../custom_utils/hparams.yaml', 'r') as f:\n",
    "    config = Namespace(**yaml.safe_load(f))\n",
    "print(torch.cuda.is_available())\n",
    "# from fast_transformers.masking import LengthMask as LM\n",
    "from custom_utils.train_pubchem_light import LightningModule\n",
    "# from openpom.utils.optimizer import get_optimizer\n",
    "# from torch import nn\n",
    "# import torch.nn.functional as F\n",
    "torch.cuda.is_available()\n",
    "torch.cuda.current_device()\n",
    "# from utils.gs_lf import *\n",
    "# import seaborn as sns\n",
    "# import pyrfume\n",
    "# from utils.util_alignment import *\n",
    "# from utils.prepare_datasets import *\n",
    "# from utils.custom_models import *\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from scipy.stats import pearsonr  \n",
    "# from sklearn.metrics import r2_score\n",
    "# import itertools\n",
    "# import math\n",
    "from utils.util_alignment import *\n",
    "# from utils.custom_models import *\n",
    "# import seaborn as sns\n",
    "# from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "# from matplotlib.patches import Patch\n",
    "# from scipy.stats import gaussian_kde\n",
    "# import numpy as np\n",
    "# import os\n",
    "# from IPython.display import Image\n",
    "# from openpom.models.mpnn_pom import MPNNPOMModel\n",
    "# plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "plt.rcParams[\"font.size\"] = 25\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "# plt.rc('font',**{'family':'serif','serif':['Times']})\n",
    "# from ast import literal_eval\n",
    "# from utils.ridge_tools import *\n",
    "# import ast\n",
    "# from scipy import stats\n",
    "# from sklearn.metrics import roc_auc_score, mean_squared_error"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "|# Loading Models"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Loading MolFormer Model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T09:37:51.722066Z",
     "start_time": "2024-06-30T09:37:51.085369Z"
    }
   },
   "source": [
    "tokenizer = MolTranBertTokenizer('../custom_utils/tokenizer/bert_vocab.txt')\n",
    "ckpt = '../MoLformer_Pretrained/checkpoints/N-Step-Checkpoint_3_30000.ckpt'\n",
    "lm = LightningModule(config, tokenizer.vocab).load_from_checkpoint(ckpt, config=config, vocab=tokenizer.vocab)"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": ""
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting embedding from MoLFormer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## helper methods"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T09:37:54.788006Z",
     "start_time": "2024-06-30T09:37:54.781051Z"
    }
   },
   "source": [
    "def convert_todf_molformer(embeddings_dataset,cids,subjects=None,y=None):\n",
    "    embeddings_dataset = pd.DataFrame(embeddings_dataset)\n",
    "    embeddings_dataset['embeddings'] = embeddings_dataset.loc[:, 0:768].values.tolist()\n",
    "    embeddings_dataset['CID'] = cids\n",
    "    if subjects is not None:\n",
    "        embeddings_dataset['subject'] = subjects\n",
    "        \n",
    "    if y is not None:\n",
    "        y_dataset = pd.DataFrame(y)\n",
    "        y_dataset['y'] = y_dataset.loc[:, 0:768].values.tolist()\n",
    "    \n",
    "        df = pd.concat([embeddings_dataset, y_dataset], axis=1)\n",
    "        return df\n",
    "    else:\n",
    "        return embeddings_dataset"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sagar"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "input_file_sagar = '/local_storage/datasets/farzaneh/alignment_olfaction_datasets/curated_datasets/mols_datasets/curated_sagar_subjects_nonaminus.csv' # or new downloaded file path\n",
    "# '/local_storage/datasets/farzaneh/alignment_olfaction_datasets/curated_datasets/embeddings/molformer/gslf_molformer_embeddings_13_Apr17.csv'\n",
    "smiles_field = 'nonStereoSMILES'\n",
    "df_sagar_temp=pd.read_csv(input_file_sagar)\n",
    "sagar_tasks= df_sagar_temp.columns.to_list()[1:16]\n",
    "cids_sagar= df_sagar_temp['cid'].values.tolist()\n",
    "subjects_sagar= df_sagar_temp['subject'].values.tolist()\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "X_sagar,y_sagar,X_layers_sagar,y_layers_sagar=extract_molformer_representations(lm, tokenizer, sagar_tasks, input_file_sagar, smiles_field)\n",
    "df_embeddings_sagar = convert_todf_molformer(X_sagar,cids_sagar,subjects_sagar,y_sagar)\n",
    "df_embeddings_sagar.to_csv('sagar_molformer_embeddings_13_Apr17.csv', index=False)\n",
    "for i,X in enumerate(X_layers_sagar):\n",
    "    print(\"i\",i)\n",
    "    df_embeddings_sagar = convert_todf_molformer(X_layers_sagar[i],cids_sagar,subjects_sagar,y_layers_sagar[i])\n",
    "    df_embeddings_sagar.to_csv('sagar_molformer_embeddings_'+str(i)+'_Apr17.csv', index=False)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# df_embeddings_sagar.columns.values"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keller"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "input_file_keller = '/local_storage/datasets/farzaneh/alignment_olfaction_datasets/curated_datasets/mols_datasets/curated_keller2016_nona.csv' # or new downloaded file path\n",
    "smiles_field = 'nonStereoSMILES'\n",
    "df_keller_temp=pd.read_csv(input_file_keller)\n",
    "keller_tasks= df_keller_temp.columns.to_list()[5:]\n",
    "cids_keller= df_keller_temp['CID'].values.tolist()\n",
    "cids_subject= df_keller_temp['Subject'].values.tolist()\n",
    "X_keller,y_keller,X_layers_keller,y_layers_keller=extract_molformer_representations(lm, tokenizer, keller_tasks, input_file_keller, smiles_field)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df_embeddings_keller = convert_todf_molformer(X_keller,cids_keller,cids_subject,y_keller)\n",
    "df_embeddings_keller.to_csv('keller_molformer_embeddings_13_Apr17.csv', index=False)\n",
    "for i,X in enumerate(X_layers_keller):\n",
    "    print(\"i\",i)\n",
    "    df_embeddings_keller = convert_todf_molformer(X_layers_keller[i],cids_keller,cids_subject,y_layers_keller[i])\n",
    "    df_embeddings_keller.to_csv('keller_molformer_embeddings_'+str(i)+'_Apr17.csv', index=False)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# df_embeddings_keller.columns.values.tolist()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ravia"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "input_file_ravia = '/local_storage/datasets/farzaneh/alignment_olfaction_datasets/curated_datasets/mols_datasets/ravia_molecules.csv'\n",
    "df_ravia_temp=pd.read_csv(input_file_ravia)\n",
    "smiles_field = 'nonStereoSMILES'\n",
    "cids_ravia= df_ravia_temp['CID'].values.tolist()\n",
    "X_ravia,y_ravia,X_layers_ravia,y_layers_ravia=extract_molformer_representations(lm, tokenizer, [], input_file_ravia, smiles_field)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df_embeddings_ravia = convert_todf_molformer(X_ravia,cids_ravia,None,y_ravia)\n",
    "df_embeddings_ravia.to_csv('ravia_molformer_embeddings_13_Apr17.csv', index=False)\n",
    "for i,X in enumerate(X_layers_ravia):\n",
    "    # print(\"i\",i)\n",
    "    df_embeddings_ravia = convert_todf_molformer(X_layers_ravia[i],cids_ravia,None,y_layers_ravia[i])\n",
    "    df_embeddings_ravia.to_csv('ravia_molformer_embeddings_'+str(i)+'_Apr17.csv', index=False)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# df_embeddings_ravia"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Snitz"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "input_file_snitz = '/local_storage/datasets/farzaneh/alignment_olfaction_datasets/curated_datasets/mols_datasets/snitz_molecules.csv'\n",
    "df_snitz_temp=pd.read_csv(input_file_snitz)\n",
    "smiles_field = 'nonStereoSMILES'\n",
    "cids_snitz= df_snitz_temp['CID'].values.tolist()\n",
    "X_snitz,y_snitz,X_layers_snitz,y_layers_snitz=extract_molformer_representations(lm, tokenizer, [], input_file_snitz, smiles_field)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df_embeddings_snitz = convert_todf_molformer(X_snitz,cids_snitz,None,y_snitz)\n",
    "df_embeddings_snitz.to_csv('snitz_molformer_embeddings_13_Apr17.csv', index=False)\n",
    "for i,X in enumerate(X_layers_snitz):\n",
    "    print(\"i\",i)\n",
    "    df_embeddings_snitz = convert_todf_molformer(X_layers_snitz[i],cids_snitz,y_layers_snitz[i])\n",
    "    df_embeddings_snitz.to_csv('snitz_molformer_embeddings_'+str(i)+'_Apr17.csv', index=False)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GS-LF"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "input_file_gslf = '/local_storage/datasets/farzaneh/alignment_olfaction_datasets/curated_datasets/mols_datasets/curated_GS_LF_merged_4983.csv' # or new downloaded file path\n",
    "smiles_field = 'nonStereoSMILES'\n",
    "df_gslf_temp=pd.read_csv(input_file_gslf)\n",
    "gslf_tasks=df_gslf_temp.columns.to_list()[2:]\n",
    "cids_gslf= df_gslf_temp.index.values.tolist()\n",
    "X_gslf,y_gslf,X_layers_gslf,y_layers_gslf=extract_molformer_representations(lm, tokenizer, gslf_tasks, input_file_gslf, smiles_field)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# df_gslf_temp.index.values.tolist()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df_embeddings_gslf = convert_todf_molformer(X_gslf,cids_gslf,None,y_gslf)\n",
    "df_embeddings_gslf.to_csv('gslf_molformer_embeddings_13_Apr17.csv', index=False)\n",
    "for i,X in enumerate(X_layers_gslf):\n",
    "    # print(\"i\",i)\n",
    "    df_embeddings_gslf = convert_todf_molformer(X_layers_gslf[i],cids_gslf,y_layers_gslf[i])\n",
    "    df_embeddings_gslf.to_csv('gslf_molformer_embeddings_'+str(i)+'_Apr17.csv', index=False)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## dravienks"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T09:44:21.473725Z",
     "start_time": "2024-06-30T09:44:19.294506Z"
    }
   },
   "source": [
    "input_file_dravienks_1 = '/local_storage/datasets/farzaneh/alignment_olfaction_datasets/curated_datasets/tasks/dravnieks1985_applicability_1.csv' # or new  \n",
    "# '/local_storage/datasets/farzaneh/alignment_olfaction_datasets/curated_datasets/embeddings/molformer/gslf_molformer_embeddings_13_Apr17.csv'\n",
    "smiles_field = 'nonStereoSMILES'\n",
    "df_dravienks_temp_1=pd.read_csv(input_file_dravienks_1)\n",
    "dravienks_tasks_1= df_dravienks_temp_1.columns.to_list()[1:-9]\n",
    "cids_dravienks= df_dravienks_temp_1['CID'].values.tolist()\n",
    "X_dravienks,y_dravienks,X_layers_dravienks,y_layers_dravienks=extract_molformer_representations(lm, tokenizer, dravienks_tasks_1, input_file_dravienks_1, smiles_field)"
   ],
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T09:44:23.439081Z",
     "start_time": "2024-06-30T09:44:21.474886Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_embeddings_dravienks = convert_todf_molformer(X_dravienks,cids_dravienks,None,y_dravienks)\n",
    "df_embeddings_dravienks.to_csv('dravienks1985App1_molformer_embeddings_13_Apr17.csv', index=False)\n",
    "for i,X in enumerate(X_layers_dravienks):\n",
    "    print(\"i\",i)\n",
    "    df_embeddings_dravienks = convert_todf_molformer(X_layers_dravienks[i],cids_dravienks,None,y_layers_dravienks[i])\n",
    "    df_embeddings_dravienks.to_csv('dravienks1985App1_molformer_embeddings_'+str(i)+'_Apr17.csv', index=False)\n"
   ],
   "execution_count": 12,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T09:44:25.592672Z",
     "start_time": "2024-06-30T09:44:23.440120Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_file_dravienks_2 = '/local_storage/datasets/farzaneh/alignment_olfaction_datasets/curated_datasets/tasks/dravnieks1985_use_2.csv' # or new downloaded file path\n",
    "# '/local_storage/datasets/farzaneh/alignment_olfaction_datasets/curated_datasets/embeddings/molformer/gslf_molformer_embeddings_13_Apr17.csv'\n",
    "smiles_field = 'nonStereoSMILES'\n",
    "df_dravienks_temp_2=pd.read_csv(input_file_dravienks_2)\n",
    "dravienks_tasks_2= df_dravienks_temp_2.columns.to_list()[1:-9]\n",
    "cids_dravienks= df_dravienks_temp_2['CID'].values.tolist()\n",
    "X_dravienks,y_dravienks,X_layers_dravienks,y_layers_dravienks=extract_molformer_representations(lm, tokenizer, dravienks_tasks_2, input_file_dravienks_2, smiles_field)"
   ],
   "execution_count": 13,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T09:44:27.561206Z",
     "start_time": "2024-06-30T09:44:25.594122Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_embeddings_dravienks = convert_todf_molformer(X_dravienks,cids_dravienks,None,y_dravienks)\n",
    "df_embeddings_dravienks.to_csv('dravienks1985Use2_molformer_embeddings_13_Apr17.csv', index=False)\n",
    "for i,X in enumerate(X_layers_dravienks):\n",
    "    print(\"i\",i)\n",
    "    df_embeddings_dravienks = convert_todf_molformer(X_layers_dravienks[i],cids_dravienks,None,y_layers_dravienks[i])\n",
    "    df_embeddings_dravienks.to_csv('dravienks1985Use2_molformer_embeddings_'+str(i)+'_Apr17.csv', index=False)"
   ],
   "execution_count": 14,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
